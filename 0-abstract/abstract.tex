In recent years, the computing landscape has seen an increasing shift towards
specialized accelerators. Reconfigurable architectures like FPGAs are
particularly promising for accelerator implementation as they can offer
performance and energy efficiency improvements over CPUs and GPUs and are more
flexible than fixed-function ASICs. Unfortunately, adoption of reconfigurable
hardware has been limited by their associated tools and programming models:
hardware description languages (HDLs) lack abstractions for productivity and are
difficult to target directly from higher level languages. High level synthesis
(HLS) tools are more productive, but offer an ad-hoc mix of software and hardware
abstractions which make even automated performance optimizations difficult.

At the same time, there has been growing demand by software engineers
and domain experts to move towards domain-specific languages (DSLs)
which provide higher levels of abstraction and hence improved programmer
productivity.
Unfortunately, domain-specific methods for generating accelerators currently
focus on library-based approaches which generate
hardware on a per-kernel basis, resulting in excessive memory transfers and
missing critical cross-kernel optimizations.

This work describes a new system for compiling applications to hardware
accelerator designs that addresses these productivity and optimization
challenges. To improve past kernel-based
approaches when starting from domain-specific languages, we
introduce a waypoint between DSLs and HDLs: a new intermediate abstraction
dedicated to representing parameterized accelerator designs
targeting reconfigurable architectures.
Starting from a common intermediate
representation for high-level DSLs based on parallel patterns, we first describe
the cross-kernel optimizations the system performs and the method it uses to
lower the entire application graph into a parameterized design in the
intermediate hardware abstraction.
We then describe our implementation of
this intermediate abstraction, a language and compiler called Spatial.
We discuss some of the compiler optimizations Spatial enables,
including rapid design parameter tuning, pipeline scheduling, and 
memory partitioning.

The system proposed in this work can compile a
high-level program in a domain-specific language into an optimized,
synthesizable hardware design for a
given FPGA target with host-side runtime administration.


In recent years, the computing landscape has seen an increasing shift towards customized datapaths and specialized accelerators. Reconfigurable architectures like field programmable gate arrays (FPGAs) and coarse-grain reconfigurable architectures (CGRAs) are particularly promising for the implementation of these accelerators, as they offer significant performance and energy improvements over CPUs and GPUs for a wide class of applications while being far more flexible than fixed-function ASICs. Unfortunately, adoption of reconfigurable architectures has been limited by their programming models. Hardware description languages (HDLs) lack abstractions for productivity and are difficult to target from higher level languages. Commercial high level synthesis (HLS) tools are more productive, but offer an ad-hoc mix of software and hardware abstractions which make both manual and compiler-based performance optimizations difficult.


Acceleration in the form of customized datapaths offer large
performance and energy improvements over general purpose
processors.



%% ASPLOS
. Field programmable gate arrays (FPGAs) are particularly promising for the implementation of these accelerators, as  However, FPGAs are difficult to program. Traditional programming models for reconfigurable logic use low-level hardware description languages like Verilog and VHDL, which have none of the productivity features of modern software languages but produce very efficient designs, and low-level software languages like C and OpenCL coupled with high-level synthesis (HLS) tools that typically produce designs that are far less efficient.

Functional languages with parallel patterns are a better fit for hardware generation because they provide high-level abstractions
to programmers with little experience in hardware design and avoid many of the problems faced when generating hardware from imperative languages.  In this paper, we identify two important optimizations for using parallel patterns to generate efficient hardware:
tiling and metapipelining.  We present a general representation of tiled parallel patterns, and provide rules for
automatically tiling patterns and generating metapipelines.
We demonstrate experimentally that these optimizations result in speedups up to
$39.4 \times$ on a set of benchmarks from the data analytics domain.

%% DHDL
Acceleration in the form of customized datapaths offer large
performance and energy improvements over general purpose
processors. Reconfigurable fabrics such as FPGAs are gaining
popularity for use in implementing application-specific accelerators, thereby
increasing the importance of having good high-level FPGA design
tools. However, current tools for targeting FPGAs offer inadequate
support for high-level programming, resource estimation,
and rapid and automatic design space exploration.

We describe a design framework that addresses these challenges. We
introduce a new representation of hardware using parameterized
templates that captures locality and parallelism information at
multiple levels of nesting. This representation is designed to be
automatically generated from high-level languages based on parallel
patterns. We describe a hybrid area estimation
technique which uses template-level models and design-level artificial neural networks
to account for effects from hardware
place-and-route tools, including routing overheads, register and block RAM
duplication, and LUT packing. Our runtime estimation accounts for
off-chip memory accesses.  We use our estimation capabilities to
rapidly explore a large space of designs across tile sizes,
parallelization factors, and optional coarse-grained pipelining, all
at multiple loop levels. We show that estimates average 4.8\% error for
logic resources, 6.1\% error for runtimes, and are 279 to 6533 times faster
than a commercial high-level synthesis tool. We compare the
best-performing designs to optimized CPU code running on a
server-grade 6 core processor and show speedups of up to $16.7\times$.


%% Spatial
Industry is increasingly turning to reconfigurable architectures like FPGAs and CGRAs for improved performance and energy
efficiency.


In this work, we describe a new domain-specific language and compiler called Spatial for higher level descriptions of application accelerators.
We describe Spatial's hardware-centric abstractions for both programmer productivity and design performance, and summarize the compiler passes required to support these abstractions, including pipeline scheduling, automatic memory banking, and automated design tuning driven by active machine learning.
We demonstrate the language's ability to target FPGAs and CGRAs from common source code. We show that applications written in Spatial
are, on average, 42\% shorter and achieve a mean speedup of $2.9\times$ over SDAccel HLS when targeting a Xilinx UltraScale+ VU9P FPGA on an Amazon EC2 F1 instance.
