In recent years, the computing landscape has seen an increasing shift towards
specialized accelerators. Reconfigurable architectures like field programmable
gate arrays (FPGAs) are particularly promising for accelerator implementation
as they can offer performance and energy efficiency improvements over CPUs
and GPUs while offering more flexibility than fixed-function ASICs.
Unfortunately, adoption of reconfigurable
hardware has been limited by their associated tools and programming models.
The conventional languages for programming FPGAs, hardware description languages (HDLs),
lack abstractions for productivity and are difficult to target directly from
higher level languages.
Commercial high level synthesis (HLS) tools
offer a more productive programming solution, but
their mix of software and hardware abstractions is ad-hoc, making both manual
and automated performance optimizations difficult.
Hardware design parameter tuning is a particularly
vital step when optimizing application accelerator designs for performance, but
neither HDLs nor HLS tools currently offer full support for compiler-aware
design paramters or automated hardware design parameter tuning.

As demand for customized accelerators has grown, so too has the
demand by software engineers and domain experts for domain-specific
languages (DSLs) which provide higher levels of abstraction and hence improved
programmer productivity.
Unfortunately, domain-specific methods for generating accelerators currently
focus on library-based approaches which generate
hardware on a per-kernel basis, resulting in excessive memory transfers and
missing critical cross-kernel optimizations.

This dissertation describes a new system for compiling high-level applications to
hardware accelerator designs that addresses these productivity and optimization
challenges. To improve results above kernel-based
approaches when programming in domain-specific languages, we
introduce a waypoint between DSLs and HDLs: a new intermediate abstraction
dedicated to representing parameterized accelerator designs
targeting reconfigurable architectures.
Starting from a common intermediate
representation for high-level DSLs based on parallel patterns, we first describe
the cross-kernel optimizations the system performs and the methods which used to
lower the entire application graph into a parameterized design in the
intermediate hardware abstraction.
We then describe our implementation of
this intermediate abstraction, a language and compiler called Spatial.
We discuss some of the compiler optimizations Spatial enables,
including rapid design parameter tuning, pipeline scheduling, and
memory banking and partitioning.
The end result is a compiler stack which can take as input a high-level program in a domain-specific
language and translate it into an optimized, synthesizable hardware design coupled with
runtime administration code for the host CPU.

We identify two key optimizations for high level compilers when
generating efficient hardware from DSLs: tiling and coarse-grained pipelining.
We present an algorithm for these optimizations when operating on programs represented
by parallel patterns, and show that they can result in improvements of up to
$39.4\times$ on a set of benchmarks from the data analytics domain.
At the hardware abstraction level, we describe a hybrid area estimation
technique which accounts for both local area costs using template models
and global routing overheads using neural network modeling.
Our runtime estimation accounts for off-chip memory accesses.
We show that estimates average 4.8\% error for logic resources,
6.1\% error for runtimes, and are obtained 279 to 6533 times faster
than a commercial high-level synthesis tool.
Finally, we show our low level compiler coupled with the Spatial hardware abstraction is
able to achieve a mean speedup of $2.9\times$ over SDAccel HLS when targeting a
Xilinx UltraScale+ VU9P FPGA on an Amazon EC2 F1 instance across a range of
dense and sparse applications.
We also show that this abstraction is more concise for hardware design for
``power'' users, with applications written directly in the
accompanying Spatial language being, on average, 42\% shorter than the
same applications written in SDAccel HLS.
