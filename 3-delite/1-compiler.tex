\section{Pattern Tiling Transformation}
\label{transformations}

One of the key challenges of generating efficient custom architectures from
high level languages is in coping with arbitrarily large data structures.
Since main memory accesses are expensive and resources on the FPGA are limited,
our goal is to store a reasonably sized working set in the FPGA's local memory
for as long as possible. Ideally, we also want to hide memory transfer latencies
by overlapping communication with computation using prefetching hardware.

To this end, we first describe a method for automatically tiling parallel
patterns to improve program locality and data reuse.
Like classic loop tiling, our pattern tiling method is composed of two
transformations: strip mining and interchange.
We assume here that our input is a PPL representation of a program and that
well known target-agnostic transformations like fusion, code motion, and struct
unwrapping have already been run.

\input{3-delite/figs/stripmining}

\subsection{Strip mining}
We first examine how parallel patterns can be strip mined.
In imperative programs, \emph{for} loops are strip mined using a single transformation
rule: split the loop's domain to create a pair of nested \emph{for} loops.
The rules for parallel pattern strip mining are similarly straightforward,
but are pattern-specific.

The strip mining algorithm is defined here using two passes over the IR.
The first pass partitions each pattern's iteration domain \emph{d} into tiles of
size \emph{b} by breaking the pattern into a pair of perfectly nested patterns.
The outer pattern operates over the strided index domain, expressed here as
\emph{d/b}, while the inner pattern operates on a tile of size \emph{b}.
For the sake of brevity this notation ignores the case where \emph{b} does not
perfectly divide \emph{d}, but this case is solved in practice with the
addition of \emph{min} checks on the domain of the inner loop.

Table~\ref{table:stripmining} gives an overview of the rules used by transformer
(denoted \emph{T}) to strip mine parallel patterns.
In addition to splitting up the domain, patterns are transformed by recursively
strip mining all functions within that pattern.
Map is strip mined by reducing its domain and range and nesting it within a MultiFold.
Note that the strided MultiFold writes to each memory location only once.
In this case, we indicate the MultiFold's combination function as unused with an underscore.

As defined in Figure~\ref{fig:ppl-syntax}, the MultiFold, GroupByFold, and FlatMap patterns have the property that a perfectly nested form of a single instance of one of these
patterns is equivalent to a single ``flattened'' form of that same pattern. This property allows these patterns to be strip mined by
breaking them up into a set of perfectly nested patterns of the same type as the original pattern.

The second strip mining pass converts array slices and accesses with statically predictable access patterns into slices and accesses of larger, explicitly defined
array memory tiles. We define tiles which have a size statically known to fit on the FPGA using array copies.
Copies generated during strip mining can then be used to infer buffers during hardware generation.
%These buffers allow better usage of burst reads and writes from main memory and enable overlapping of compututation and communication using hardware prefetching.
Array tiles which have overlap, such as those generated from sliding windows in convolution, are marked with metadata in the IR as having some reuse factor.
Array copies with reuse have generation rules which minimize the number of redundant reads to main memory when possible.

\input{3-delite/figs/stripexamples}

Table~\ref{table:stripmine-examples} demonstrates how our rules can be used to strip mine a set of simple data parallel operations.
We use the \emph{copy} infix function on arrays to designate array copies in these examples, using similar syntax as array \emph{slice}.
We assume in these examples that common subexpression elimination (CSE) and code motion transformation passes have been run after strip mining to eliminate duplicate copies and to
move array tiles out of the innermost patterns. In these examples, strip mining creates tiled copies of input collections that
we can later directly use to infer read buffers.

\subsection{Pattern Interchange}
Given an intermediate representation with strip mined nested parallel patterns, we now need to interchange patterns to increase the reuse
of newly created data tiles. This can be achieved by moving strided patterns out of unstrided patterns. However, as with imperative loops,
it is not sound to arbitrarily change the order of nested parallel patterns.
We use two rules for pattern interchange adapted from a previously established \emph{Collect}-\emph{Reduce} reordering rule for computation on clusters~\cite{brown16clusters}.
These rules both match on the special case of MultiFold where every iteration updates the entire accumulator, which we refer to here as a \emph{fold}.
The first interchange rule defines how to move a scalar, strided \emph{fold} out of an unstrided Map, transforming the nested loop into a strided \emph{fold} of a Map.
Note that this also changes the combination function of the \emph{fold} into a Map.
The second rule is the inverse of the first, allowing us to reorder a strided MultiFold with no reduction function (i.e. the outer pattern of a tiled Map)
out of an unstrided \emph{fold}. This creates a strided MultiFold of a scalar \emph{fold}. We apply these two rules whenever possible to increase the reuse
of tiled inputs.

Imperfectly nested parallel patterns commonly occur either due to the way the original user program was structured or
as a result of aggressive vertical fusion run prior to tiling.
Interchange on imperfectly nested patterns requires splitting patterns into perfectly nested sections. However, splitting and reordering trades
temporal locality of intermediate values for increased reuse of data tiles. In hardware, this can involve creating more main memory
reads or larger on-chip buffers for intermediate results so that less reads need to be done for input and output data. This tradeoff between memory reads and
increased buffer usage requires more complex cost modeling.
We use a simple heuristic to determine whether to split fused loops: we split and interchange patterns only when
the intermediate result created after splitting and interchanging is statically known to fit on the FPGA. This handles the simple case
where the FPGA has unused on-chip buffers and allocating more on-chip memory guarantees a decrease in the number of main memory reads.
Future work will examine ways to statically model the tradeoff between main memory accesses and local buffers near 100\% on-chip memory utilization.

\input{3-delite/figs/interchange}

Figure~\ref{fig:interchange-examples} shows a simple example of the application of our pattern interchange rules on matrix multiplication.
We assume here that code motion has been run again after pattern interchange has completed.
In matrix multiplication, we interchange the perfectly nested strided MultiFold and the unstrided Map.
This ordering increases the reuse of the copied tile of matrix \emph{y} and changes the scalar reduction into a tile-wise reduction.
Note that the partial result calculation and the inner reduction can now be vertically fused.


\begin{figure}\small\centering
\input{3-delite/figs/tilingKmeans}
\caption{Tiling example for the core of $k$-means clustering starting from the
fused representation in Figure~\ref{fig:kmeans-fused}, using tile sizes of
\emph{b$_0$} and \emph{b$_1$} for the number of points $n$ and the number of
clusters $k$. The number of features $d$ is not tiled in this example.}
\label{fig:kmeans-example}
\end{figure}

\subsection{Example} We conclude this section with an example of tiling
the $k$-means clustering algorithm, starting from the fused representation
introduced in Figure~\ref{fig:kmeans-fused}. We assume here that we wish
to tile the number of input points, \emph{n}, with tile size \emph{b$_0$} and
the number of clusters, \emph{k}, with tile size \emph{b$_1$} but not the
number of dimensions, \emph{d}. This is representative of machine learning
classification problems where the number of input points and number of labels is
large, but the number of features for each point is relatively small.

Figure~\ref{fig:kmeans-example} gives a comparison of the $k$-means clustering
algorithm after strip mining and after pattern interchange. During strip mining,
we create tiles for both the \emph{points} and \emph{centroids} arrays, which
helps us to take advantage of main memory burst reads. However, in the strip
mined version, we still fully calculate the closest centroid for each point.
This requires the entirety of \emph{centroids} to be read for each point.
We increase the reuse of each tile of \emph{centroids} by first splitting
the calculation of the closest centroid label from the MultiFold
(Figure~\ref{fig:kmeans-example}a. line~5). The iteration over the centroids
tile is then perfectly nested within the iteration over the points.
Interchanging these two iterations allows us to reuse the centroids tile across
points, thus decreasing the total number of main memory reads for this array
by a factor of \emph{b$_0$}. This decrease comes
at the expense of changing the intermediate (distance, label) pair for a single
point to a set of intermediate pairs for an entire tile of \emph{points}.
Since the created intermediate result
has size 2\emph{b$_0$}, we statically determine that this is an advantageous
tradeoff and use the split and interchanged form of the algorithm.

Note that while the rules we outline here for automatic tiling of parallel patterns are
target-agnostic. However, tile copies should only be made explicit for devices
with scratchpad memory. Architectures with hierarchical memory systems
effectively maintain views of subsections of memory automatically through
caching, making explicit copies on these architectures a waste of both
compute cycles and memory. We discuss how tile sizes like \emph{b$_0$} and
\emph{b$_1$} can be selected automatically in Chapter~\todo{?}.
